{"cells":[{"cell_type":"markdown","metadata":{},"source":["# 金融异常检测任务"]},{"cell_type":"markdown","metadata":{},"source":["## 1. 实验介绍\n","\n","反欺诈是金融行业永恒的主题，在互联网金融信贷业务中，数字金融反欺诈技术已经得到广泛应用并取得良好效果，这其中包括了近几年迅速发展并在各个领域\n","得到越来越广泛应用的神经网络。本项目以互联网智能风控为背景，从用户相互关联和影响的视角，探索满足风控反欺诈领域需求的，可拓展、高效的神经\n","网络应用方案，从而帮助更好地识别欺诈用户。\n","\n","本项目主要关于实现预测模型(**项目用图神经网络举例，具体实现可以使用其他模型**)，进行节点异常检测任务，并验证模型精度。而本项目基于的数据集[DGraph](https://dgraph.xinye.com/introduction)，[DGraph](https://dgraph.xinye.com/introduction)\n","是大规模动态图数据集的集合，由真实金融场景中随着时间演变事件和标签构成。\n","\n","### 1.1 实验目的\n","\n","- 了解如何使用Pytorch进行神经网络训练\n","- 了解如何使用Pytorch-geometric等图网络深度学习库进行简单图神经网络设计(推荐使用GAT, GraphSAGE模型)。\n","- 了解如何利用MO平台进行模型性能评估。\n","\n","### 1.2 预备知识\n","- 具备一定的深度学习理论知识，如卷积神经网络、损失函数、优化器，训练策略等。\n","- 了解并熟悉Pytorch计算框架。\n","- 学习Pytorch-geometric，请前往：https://pytorch-geometric.readthedocs.io/en/latest/\n","    \n","### 1.3实验环境\n","- numpy = 1.26.4  \n","- pytorch = 2.3.1  \n","- torch_geometric = 2.5.3  \n","- torch_scatter = 2.1.2  \n","- torch_sparse = 0.6.18  "]},{"cell_type":"markdown","metadata":{},"source":["## 2. 实验内容"]},{"cell_type":"markdown","metadata":{},"source":["### 2.1 数据集信息\n","DGraph-Fin 是一个由数百万个节点和边组成的有向无边权的动态图。它代表了Finvolution Group用户之间的社交网络，其中一个节点对应一个Finvolution 用户，从一个用户到另一个用户的边表示**该用户将另一个用户视为紧急联系人**。\n","下面是`位于dataset/DGraphFin目录`的DGraphFin数据集的描述:\n","```\n","x:  20维节点特征向量\n","y:  节点对应标签，一共包含四类。其中类1代表欺诈用户而类0代表正常用户(实验中需要进行预测的两类标签)，类2和类3则是背景用户，即无需预测其标签。\n","edge_index:  图数据边集,每条边的形式(id_a,id_b)，其中ids是x中的索引\n","edge_type: 共11种类型的边\n","edge_timestamp: 脱敏后的时间戳\n","train_mask, valid_mask, test_mask: 训练集，验证集和测试集掩码\n","```\n","本预测任务为识别欺诈用户的节点预测任务,只需要将欺诈用户（Class 1）从正常用户（Class 0）中区分出来。需要注意的是，其中测试集中样本对应的label**均被标记为-100**。"]},{"cell_type":"markdown","metadata":{"toc-hr-collapsed":false},"source":["### 2.2 导入相关包\n","\n","导入相应模块，设置数据集路径、设备等。"]},{"cell_type":"code","execution_count":1,"id":"2ec8f762","metadata":{},"outputs":[],"source":["from utils import DGraphFin\n","from utils.utils import prepare_folder\n","from utils.evaluator import Evaluator\n","\n","import torch\n","import torch.nn.functional as F\n","import torch.nn as nn\n","\n","import torch_geometric.transforms as T\n","\n","import numpy as np\n","from torch_geometric.data import Data\n","import os\n","\n","#设置gpu设备\n","device = 0\n","device = f'cuda:{device}' if torch.cuda.is_available() else 'cpu'\n","device = torch.device(device)\n"]},{"cell_type":"markdown","metadata":{},"source":["### 2.3 数据处理\n","\n","在使用数据集训练网络前，首先需要对数据进行归一化等预处理，如下："]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"ename":"AttributeError","evalue":"'Tensor' object has no attribute 'to_symmetric'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[5], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m     nlabels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m    \u001b[38;5;66;03m#本实验中仅需预测类0和类1\u001b[39;00m\n\u001b[1;32m     10\u001b[0m data \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 11\u001b[0m data\u001b[38;5;241m.\u001b[39madj_t \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madj_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_symmetric\u001b[49m() \u001b[38;5;66;03m#将有向图转化为无向图\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dataset_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDGraph\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     16\u001b[0m     x \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx\n","\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'to_symmetric'"]}],"source":["path='./datasets/632d74d4e2843a53167ee9a1-momodel/' #数据保存路径\n","save_dir='./results/' #模型保存路径\n","dataset_name='DGraph'\n","dataset = DGraphFin(root=path, name=dataset_name, transform=T.ToSparseTensor())\n","\n","nlabels = dataset.num_classes\n","if dataset_name in ['DGraph']:\n","    nlabels = 2    #本实验中仅需预测类0和类1\n","\n","data = dataset[0]\n","data.adj_t = data.adj_t.to_symmetric() #将有向图转化为无向图\n","\n","\n","\n","if dataset_name in ['DGraph']:\n","    x = data.x\n","    x = (x - x.mean(0)) / x.std(0)\n","    data.x = x\n","if data.y.dim() == 2:\n","    data.y = data.y.squeeze(1)\n","\n","split_idx = {'train': data.train_mask, 'valid': data.valid_mask, 'test': data.test_mask}  #划分训练集，验证集\n","\n","train_idx = split_idx['train']\n","result_dir = prepare_folder(dataset_name,'mlp')\n"]},{"cell_type":"markdown","metadata":{},"source":["这里我们可以查看数据各部分维度"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Data(x=[3700550, 20], edge_attr=[4300999], y=[3700550, 1], train_mask=[857899], valid_mask=[183862], test_mask=[183840], adj_t=[3700550, 3700550])\n","torch.Size([3700550, 20])\n","torch.Size([3700550, 1])\n"]}],"source":["print(data)\n","print(data.x.shape)  #feature\n","print(data.y.shape)  #label\n"]},{"cell_type":"markdown","metadata":{},"source":["### 2.4 定义模型\n","这里我们使用简单的多层感知机作为例子："]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["class MLP(torch.nn.Module):\n","    def __init__(self\n","                 , in_channels\n","                 , hidden_channels\n","                 , out_channels\n","                 , num_layers\n","                 , dropout\n","                 , batchnorm=True):\n","        super(MLP, self).__init__()\n","        self.lins = torch.nn.ModuleList()\n","        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n","        self.batchnorm = batchnorm\n","        if self.batchnorm:\n","            self.bns = torch.nn.ModuleList()\n","            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n","        for _ in range(num_layers - 2):\n","            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n","            if self.batchnorm:\n","                self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n","        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n","\n","        self.dropout = dropout\n","\n","    def reset_parameters(self):\n","        for lin in self.lins:\n","            lin.reset_parameters()\n","        if self.batchnorm:\n","            for bn in self.bns:\n","                bn.reset_parameters()\n","\n","    def forward(self, x):\n","        for i, lin in enumerate(self.lins[:-1]):\n","            x = lin(x)\n","            if self.batchnorm:\n","                x = self.bns[i](x)\n","            x = F.relu(x)\n","            x = F.dropout(x, p=self.dropout, training=self.training)\n","        x = self.lins[-1](x)\n","        return F.log_softmax(x, dim=-1)\n"]},{"cell_type":"markdown","metadata":{},"source":["配置后续训练、验证、推理用到的参数。可以调整以下超参以提高模型训练后的验证精度：\n","\n","- `epochs`：在训练集上训练的代数；\n","- `lr`：学习率；\n","- `num_layers`：网络的层数；\n","- `hidden_channels`：隐藏层维数；\n","- `dropout`：dropout比例；\n","- `weight_decay`：正则化项的系数。"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["mlp_parameters = {\n","    'lr': 0.01\n","    , 'num_layers': 2\n","    , 'hidden_channels': 128\n","    , 'dropout': 0.0\n","    , 'batchnorm': False\n","    , 'weight_decay': 5e-7\n","                  }\n","epochs = 200\n","log_steps =10 # log记录周期\n"]},{"cell_type":"markdown","metadata":{},"source":["初始化模型，并使用**Area Under the Curve (AUC)** 作为模型评价指标来衡量模型的表现。AUC通过对ROC曲线下各部分的面积求和而得。\n","\n","具体计算过程参见 https://github.com/scikit-learn/scikit-learn/blob/baf828ca1/sklearn/metrics/_ranking.py#L363"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model MLP initialized\n"]}],"source":["para_dict = mlp_parameters\n","model_para = mlp_parameters.copy()\n","model_para.pop('lr')\n","model_para.pop('weight_decay')\n","model = MLP(in_channels=data.x.size(-1), out_channels=nlabels, **model_para).to(device)\n","print(f'Model MLP initialized')\n","\n","\n","eval_metric = 'auc'  #使用AUC衡量指标\n","evaluator = Evaluator(eval_metric)\n"]},{"cell_type":"markdown","metadata":{},"source":["### 2.5 训练\n","\n","使用训练集中的节点用于训练模型，并使用验证集进行挑选模型。"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def train(model, data, train_idx, optimizer):\n","     # data.y is labels of shape (N, )\n","    model.train()\n","\n","    optimizer.zero_grad()\n","\n","    out = model(data.x[train_idx])\n","\n","    loss = F.nll_loss(out, data.y[train_idx])\n","    loss.backward()\n","    optimizer.step()\n","\n","    return loss.item()\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["def test(model, data, split_idx, evaluator):\n","    # data.y is labels of shape (N, )\n","    with torch.no_grad():\n","        model.eval()\n","\n","        losses, eval_results = dict(), dict()\n","        for key in ['train', 'valid']:\n","            node_id = split_idx[key]\n","\n","            out = model(data.x[node_id])\n","            y_pred = out.exp()  # (N,num_classes)\n","\n","            losses[key] = F.nll_loss(out, data.y[node_id]).item()\n","            eval_results[key] = evaluator.eval(data.y[node_id], y_pred)[eval_metric]\n","\n","    return eval_results, losses, y_pred\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["2946\n"]},{"ename":"NameError","evalue":"name 'train_idx' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[12], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m min_valid_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e8\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 9\u001b[0m     loss \u001b[38;5;241m=\u001b[39m train(model, data, \u001b[43mtrain_idx\u001b[49m, optimizer)\n\u001b[1;32m     10\u001b[0m     eval_results, losses, out \u001b[38;5;241m=\u001b[39m test(model, data, split_idx, evaluator)\n\u001b[1;32m     11\u001b[0m     train_eval, valid_eval \u001b[38;5;241m=\u001b[39m eval_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m], eval_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m]\n","\u001b[0;31mNameError\u001b[0m: name 'train_idx' is not defined"]}],"source":["print(sum(p.numel() for p in model.parameters()))  #模型总参数量\n","\n","model.reset_parameters()\n","optimizer = torch.optim.Adam(model.parameters(), lr=para_dict['lr'], weight_decay=para_dict['weight_decay'])\n","best_valid = 0\n","min_valid_loss = 1e8\n","\n","for epoch in range(1,epochs + 1):\n","    loss = train(model, data, train_idx, optimizer)\n","    eval_results, losses, out = test(model, data, split_idx, evaluator)\n","    train_eval, valid_eval = eval_results['train'], eval_results['valid']\n","    train_loss, valid_loss = losses['train'], losses['valid']\n","\n","    if valid_loss < min_valid_loss:\n","        min_valid_loss = valid_loss\n","        torch.save(model.state_dict(), save_dir+'/model.pt') #将表现最好的模型保存\n","\n","    if epoch % log_steps == 0:\n","        print(f'Epoch: {epoch:02d}, '\n","              f'Loss: {loss:.4f}, '\n","              f'Train: {100 * train_eval:.3f}, ' # 我们将AUC值乘上100，使其在0-100的区间内\n","              f'Valid: {100 * valid_eval:.3f} ')\n"]},{"cell_type":"markdown","metadata":{"inputHidden":false},"source":["### 2.6 模型预测"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_364505/3090378226.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(save_dir+'/model.pt')) #载入验证集上表现最好的模型\n"]},{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: './results//model.pt'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/model.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m) \u001b[38;5;66;03m#载入验证集上表现最好的模型\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(data,node_id):\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    加载模型和模型预测\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m    :param node_id: int, 需要进行预测节点的下标\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m    :return: tensor, 类0以及类1的概率, torch.size[1,2]\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/zju_ai_sys/lib/python3.12/site-packages/torch/serialization.py:1065\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1063\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1065\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1067\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n","File \u001b[0;32m~/anaconda3/envs/zju_ai_sys/lib/python3.12/site-packages/torch/serialization.py:468\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 468\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n","File \u001b[0;32m~/anaconda3/envs/zju_ai_sys/lib/python3.12/site-packages/torch/serialization.py:449\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './results//model.pt'"]}],"source":["model.load_state_dict(torch.load(save_dir+'/model.pt')) #载入验证集上表现最好的模型\n","def predict(data,node_id):\n","    \"\"\"\n","    加载模型和模型预测\n","    :param node_id: int, 需要进行预测节点的下标\n","    :return: tensor, 类0以及类1的概率, torch.size[1,2]\n","    \"\"\"\n","    # -------------------------- 实现模型预测部分的代码 ---------------------------\n","    with torch.no_grad():\n","        model.eval()\n","        out = model(data.x[node_id])\n","        y_pred = out.exp()  # (N,num_classes)\n","\n","    return y_pred\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'predict' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m dic\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m0\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m正常用户\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m1\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m欺诈用户\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m      2\u001b[0m node_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 3\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m(data, node_idx)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_pred)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m节点 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 预测对应的标签为:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39margmax(y_pred)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, 为\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdic[torch\u001b[38;5;241m.\u001b[39margmax(y_pred)\u001b[38;5;241m.\u001b[39mitem()]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m。\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'predict' is not defined"]}],"source":["dic={0:\"正常用户\",1:\"欺诈用户\"}\n","node_idx = 0\n","y_pred = predict(data, node_idx)\n","print(y_pred)\n","print(f'节点 {node_idx} 预测对应的标签为:{torch.argmax(y_pred)}, 为{dic[torch.argmax(y_pred).item()]}。')\n","\n","node_idx = 1\n","y_pred = predict(data, node_idx)\n","print(y_pred)\n","print(f'节点 {node_idx} 预测对应的标签为:{torch.argmax(y_pred)}, 为{dic[torch.argmax(y_pred).item()]}。')\n"]},{"cell_type":"markdown","metadata":{},"source":["## 3. 作业评分\n","\n","**作业要求**：    \n","                         \n","1. 请加载你认为训练最佳的模型（不限于图神经网络)\n","2. 提交的作业包括【程序报告.pdf】和代码文件。\n","\n","**注意：**\n","          \n","1. 在训练模型等过程中如果需要**保存数据、模型**等请写到 **results** 文件夹，如果采用 [离线任务](https://momodel.cn/docs/#/zh-cn/%E5%9C%A8GPU%E6%88%96CPU%E8%B5%84%E6%BA%90%E4%B8%8A%E8%AE%AD%E7%BB%83%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B) 请务必将模型保存在 **results** 文件夹下。\n","2. 训练出自己最好的模型后，先按照下列 cell 操作方式实现 NoteBook 加载模型测试；请测试通过在进行【系统测试】。\n","3. 点击左侧栏`提交作业`后点击`生成文件`则只需勾选 `predict()` 函数的cell，即【**模型预测代码答题区域**】的 cell。\n","4. 请导入必要的包和第三方库 (包括此文件中曾经导入过的)。\n","5. 请加载你认为训练最佳的模型，即请按要求填写**模型路径**。\n","6. `predict()`函数的输入和输出请不要改动。"]},{"cell_type":"markdown","metadata":{},"source":["===========================================  **模型预测代码答题区域**  =========================================== \n","\n","在下方的代码块中编写 **模型预测** 部分的代码，请勿在别的位置作答"]},{"cell_type":"code","execution_count":15,"metadata":{"select":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_364505/1505612752.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model = model.load_state_dict(torch.load('./results/model.pt'))\n"]},{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: './results/model.pt'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# 这里可以加载你的模型\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./results/model.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(data,node_id):\n\u001b[1;32m     16\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    加载模型和模型预测\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m    :param node_id: int, 需要进行预测节点的下标\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    :return: tensor, 类0以及类1的概率, torch.size[1,2]\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/zju_ai_sys/lib/python3.12/site-packages/torch/serialization.py:1065\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1063\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1065\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1067\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n","File \u001b[0;32m~/anaconda3/envs/zju_ai_sys/lib/python3.12/site-packages/torch/serialization.py:468\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 468\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n","File \u001b[0;32m~/anaconda3/envs/zju_ai_sys/lib/python3.12/site-packages/torch/serialization.py:449\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './results/model.pt'"]}],"source":["## 生成 main.py 时请勾选此 cell\n","from utils import DGraphFin\n","from utils.evaluator import Evaluator\n","import torch\n","import torch.nn.functional as F\n","import torch.nn as nn\n","import torch_geometric.transforms as T\n","from torch_geometric.data import Data\n","import numpy as np\n","import os\n","\n","# 这里可以加载你的模型\n","model = model.load_state_dict(torch.load('./results/model.pt'))\n","\n","def predict(data,node_id):\n","    \"\"\"\n","    加载模型和模型预测\n","    :param node_id: int, 需要进行预测节点的下标\n","    :return: tensor, 类0以及类1的概率, torch.size[1,2]\n","    \"\"\"\n","\n","    # 模型预测时，测试数据已经进行了归一化处理\n","    # -------------------------- 实现模型预测部分的代码 ---------------------------\n","    with torch.no_grad():\n","        model.eval()\n","        out = model(data.x[node_id])\n","        y_pred = out.exp()  # (N,num_classes)\n","\n","    return y_pred\n"]}],"metadata":{"kernelspec":{"display_name":"zju_ai_sys","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.6"}},"nbformat":4,"nbformat_minor":5}
