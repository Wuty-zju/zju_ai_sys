{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f9335f5",
   "metadata": {},
   "source": [
    "# 金融异常检测任务"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616d05e6",
   "metadata": {},
   "source": [
    "## 1. 实验介绍\n",
    "\n",
    "反欺诈是金融行业永恒的主题，在互联网金融信贷业务中，数字金融反欺诈技术已经得到广泛应用并取得良好效果，这其中包括了近几年迅速发展并在各个领域\n",
    "得到越来越广泛应用的神经网络。本项目以互联网智能风控为背景，从用户相互关联和影响的视角，探索满足风控反欺诈领域需求的，可拓展、高效的神经\n",
    "网络应用方案，从而帮助更好地识别欺诈用户。\n",
    "\n",
    "本项目主要关于实现预测模型(**项目用图神经网络举例，具体实现可以使用其他模型**)，进行节点异常检测任务，并验证模型精度。而本项目基于的数据集[DGraph](https://dgraph.xinye.com/introduction)，[DGraph](https://dgraph.xinye.com/introduction)\n",
    "是大规模动态图数据集的集合，由真实金融场景中随着时间演变事件和标签构成。\n",
    "\n",
    "### 1.1 实验目的\n",
    "\n",
    "- 了解如何使用Pytorch进行神经网络训练\n",
    "- 了解如何使用Pytorch-geometric等图网络深度学习库进行简单图神经网络设计(推荐使用GAT, GraphSAGE模型)。\n",
    "- 了解如何利用MO平台进行模型性能评估。\n",
    "\n",
    "### 1.2 预备知识\n",
    "- 具备一定的深度学习理论知识，如卷积神经网络、损失函数、优化器，训练策略等。\n",
    "- 了解并熟悉Pytorch计算框架。\n",
    "- 学习Pytorch-geometric，请前往：https://pytorch-geometric.readthedocs.io/en/latest/\n",
    "    \n",
    "### 1.3实验环境\n",
    "- numpy = 1.26.4  \n",
    "- pytorch = 2.3.1  \n",
    "- torch_geometric = 2.5.3  \n",
    "- torch_scatter = 2.1.2  \n",
    "- torch_sparse = 0.6.18  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f9889a",
   "metadata": {},
   "source": [
    "## 2. 实验内容"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddc4b09",
   "metadata": {},
   "source": [
    "### 2.1 数据集信息\n",
    "DGraph-Fin 是一个由数百万个节点和边组成的有向无边权的动态图。它代表了Finvolution Group用户之间的社交网络，其中一个节点对应一个Finvolution 用户，从一个用户到另一个用户的边表示**该用户将另一个用户视为紧急联系人**。\n",
    "下面是`位于dataset/DGraphFin目录`的DGraphFin数据集的描述:\n",
    "```\n",
    "x:  20维节点特征向量\n",
    "y:  节点对应标签，一共包含四类。其中类1代表欺诈用户而类0代表正常用户(实验中需要进行预测的两类标签)，类2和类3则是背景用户，即无需预测其标签。\n",
    "edge_index:  图数据边集,每条边的形式(id_a,id_b)，其中ids是x中的索引\n",
    "edge_type: 共11种类型的边\n",
    "edge_timestamp: 脱敏后的时间戳\n",
    "train_mask, valid_mask, test_mask: 训练集，验证集和测试集掩码\n",
    "```\n",
    "本预测任务为识别欺诈用户的节点预测任务,只需要将欺诈用户（Class 1）从正常用户（Class 0）中区分出来。需要注意的是，其中测试集中样本对应的label**均被标记为-100**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9d1acc",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### 2.2 导入相关包\n",
    "\n",
    "导入相应模块，设置数据集路径、设备等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7c80d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import DGraphFin\n",
    "from utils.utils import prepare_folder\n",
    "from utils.evaluator import Evaluator\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "import os\n",
    "\n",
    "#设置gpu设备\n",
    "device = 0\n",
    "device = f'cuda:{device}' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fea8fba",
   "metadata": {},
   "source": [
    "### 2.3 数据处理\n",
    "\n",
    "在使用数据集训练网络前，首先需要对数据进行归一化等预处理，如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc961c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wuty/zju_ai_sys/financial_abnormality_detection/utils/dgraphfin.py:61: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0])\n"
     ]
    }
   ],
   "source": [
    "path='./datasets/632d74d4e2843a53167ee9a1-momodel/' #数据保存路径\n",
    "save_dir='./results/' #模型保存路径\n",
    "dataset_name='DGraph'\n",
    "dataset = DGraphFin(root=path, name=dataset_name, transform=T.ToSparseTensor())\n",
    "\n",
    "nlabels = dataset.num_classes\n",
    "if dataset_name in ['DGraph']:\n",
    "    nlabels = 2    #本实验中仅需预测类0和类1\n",
    "\n",
    "data = dataset[0]\n",
    "data.adj_t = data.adj_t.to_symmetric() #将有向图转化为无向图\n",
    "\n",
    "\n",
    "if dataset_name in ['DGraph']:\n",
    "    x = data.x\n",
    "    x = (x - x.mean(0)) / x.std(0)\n",
    "    data.x = x\n",
    "if data.y.dim() == 2:\n",
    "    data.y = data.y.squeeze(1)\n",
    "\n",
    "split_idx = {'train': data.train_mask, 'valid': data.valid_mask, 'test': data.test_mask}  #划分训练集，验证集\n",
    "\n",
    "train_idx = split_idx['train']\n",
    "result_dir = prepare_folder(dataset_name,'mlp')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb86fbda",
   "metadata": {},
   "source": [
    "这里我们可以查看数据各部分维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c9c99cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[3700550, 20], edge_attr=[4300999], y=[3700550], train_mask=[857899], valid_mask=[183862], test_mask=[183840], adj_t=[3700550, 3700550, nnz=7994520])\n",
      "torch.Size([3700550, 20])\n",
      "torch.Size([3700550])\n"
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "print(data.x.shape)  #feature\n",
    "print(data.y.shape)  #label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed014c88",
   "metadata": {},
   "source": [
    "### 2.4 定义模型\n",
    "这里我们使用简单的多层感知机作为例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623d2e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self\n",
    "                 , in_channels\n",
    "                 , hidden_channels\n",
    "                 , out_channels\n",
    "                 , num_layers\n",
    "                 , dropout\n",
    "                 , batchnorm=True):\n",
    "        super(MLP, self).__init__()\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n",
    "        self.batchnorm = batchnorm\n",
    "        if self.batchnorm:\n",
    "            self.bns = torch.nn.ModuleList()\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
    "            if self.batchnorm:\n",
    "                self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "        if self.batchnorm:\n",
    "            for bn in self.bns:\n",
    "                bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, lin in enumerate(self.lins[:-1]):\n",
    "            x = lin(x)\n",
    "            if self.batchnorm:\n",
    "                x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        return F.log_softmax(x, dim=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4789289",
   "metadata": {},
   "source": [
    "配置后续训练、验证、推理用到的参数。可以调整以下超参以提高模型训练后的验证精度：\n",
    "\n",
    "- `epochs`：在训练集上训练的代数；\n",
    "- `lr`：学习率；\n",
    "- `num_layers`：网络的层数；\n",
    "- `hidden_channels`：隐藏层维数；\n",
    "- `dropout`：dropout比例；\n",
    "- `weight_decay`：正则化项的系数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b235adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_parameters = {\n",
    "    'lr': 0.01\n",
    "    , 'num_layers': 2\n",
    "    , 'hidden_channels': 128\n",
    "    , 'dropout': 0.0\n",
    "    , 'batchnorm': False\n",
    "    , 'weight_decay': 5e-7\n",
    "                  }\n",
    "epochs = 200\n",
    "log_steps =10 # log记录周期\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ea5c53",
   "metadata": {},
   "source": [
    "初始化模型，并使用**Area Under the Curve (AUC)** 作为模型评价指标来衡量模型的表现。AUC通过对ROC曲线下各部分的面积求和而得。\n",
    "\n",
    "具体计算过程参见 https://github.com/scikit-learn/scikit-learn/blob/baf828ca1/sklearn/metrics/_ranking.py#L363"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9699d77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "para_dict = mlp_parameters\n",
    "model_para = mlp_parameters.copy()\n",
    "model_para.pop('lr')\n",
    "model_para.pop('weight_decay')\n",
    "model = MLP(in_channels=data.x.size(-1), out_channels=nlabels, **model_para).to(device)\n",
    "print(f'Model MLP initialized')\n",
    "\n",
    "\n",
    "eval_metric = 'auc'  #使用AUC衡量指标\n",
    "evaluator = Evaluator(eval_metric)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3adc628",
   "metadata": {},
   "source": [
    "### 2.5 训练\n",
    "\n",
    "使用训练集中的节点用于训练模型，并使用验证集进行挑选模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ac7e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, train_idx, optimizer):\n",
    "     # data.y is labels of shape (N, )\n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    out = model(data.x[train_idx])\n",
    "\n",
    "    loss = F.nll_loss(out, data.y[train_idx])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5c8cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data, split_idx, evaluator):\n",
    "    # data.y is labels of shape (N, )\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        losses, eval_results = dict(), dict()\n",
    "        for key in ['train', 'valid']:\n",
    "            node_id = split_idx[key]\n",
    "\n",
    "            out = model(data.x[node_id])\n",
    "            y_pred = out.exp()  # (N,num_classes)\n",
    "\n",
    "            losses[key] = F.nll_loss(out, data.y[node_id]).item()\n",
    "            eval_results[key] = evaluator.eval(data.y[node_id], y_pred)[eval_metric]\n",
    "\n",
    "    return eval_results, losses, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54001018",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(p.numel() for p in model.parameters()))  #模型总参数量\n",
    "\n",
    "model.reset_parameters()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=para_dict['lr'], weight_decay=para_dict['weight_decay'])\n",
    "best_valid = 0\n",
    "min_valid_loss = 1e8\n",
    "\n",
    "for epoch in range(1,epochs + 1):\n",
    "    loss = train(model, data, train_idx, optimizer)\n",
    "    eval_results, losses, out = test(model, data, split_idx, evaluator)\n",
    "    train_eval, valid_eval = eval_results['train'], eval_results['valid']\n",
    "    train_loss, valid_loss = losses['train'], losses['valid']\n",
    "\n",
    "    if valid_loss < min_valid_loss:\n",
    "        min_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), save_dir+'/model.pt') #将表现最好的模型保存\n",
    "\n",
    "    if epoch % log_steps == 0:\n",
    "        print(f'Epoch: {epoch:02d}, '\n",
    "              f'Loss: {loss:.4f}, '\n",
    "              f'Train: {100 * train_eval:.3f}, ' # 我们将AUC值乘上100，使其在0-100的区间内\n",
    "              f'Valid: {100 * valid_eval:.3f} ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57237da",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "### 2.6 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67095d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(save_dir+'/model.pt')) #载入验证集上表现最好的模型\n",
    "def predict(data,node_id):\n",
    "    \"\"\"\n",
    "    加载模型和模型预测\n",
    "    :param node_id: int, 需要进行预测节点的下标\n",
    "    :return: tensor, 类0以及类1的概率, torch.size[1,2]\n",
    "    \"\"\"\n",
    "    # -------------------------- 实现模型预测部分的代码 ---------------------------\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        out = model(data.x[node_id])\n",
    "        y_pred = out.exp()  # (N,num_classes)\n",
    "\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa60561",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic={0:\"正常用户\",1:\"欺诈用户\"}\n",
    "node_idx = 0\n",
    "y_pred = predict(data, node_idx)\n",
    "print(y_pred)\n",
    "print(f'节点 {node_idx} 预测对应的标签为:{torch.argmax(y_pred)}, 为{dic[torch.argmax(y_pred).item()]}。')\n",
    "\n",
    "node_idx = 1\n",
    "y_pred = predict(data, node_idx)\n",
    "print(y_pred)\n",
    "print(f'节点 {node_idx} 预测对应的标签为:{torch.argmax(y_pred)}, 为{dic[torch.argmax(y_pred).item()]}。')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc62365",
   "metadata": {},
   "source": [
    "## 3. 作业评分\n",
    "\n",
    "**作业要求**：    \n",
    "                         \n",
    "1. 请加载你认为训练最佳的模型（不限于图神经网络)\n",
    "2. 提交的作业包括【程序报告.pdf】和代码文件。\n",
    "\n",
    "**注意：**\n",
    "          \n",
    "1. 在训练模型等过程中如果需要**保存数据、模型**等请写到 **results** 文件夹，如果采用 [离线任务](https://momodel.cn/docs/#/zh-cn/%E5%9C%A8GPU%E6%88%96CPU%E8%B5%84%E6%BA%90%E4%B8%8A%E8%AE%AD%E7%BB%83%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B) 请务必将模型保存在 **results** 文件夹下。\n",
    "2. 训练出自己最好的模型后，先按照下列 cell 操作方式实现 NoteBook 加载模型测试；请测试通过在进行【系统测试】。\n",
    "3. 点击左侧栏`提交作业`后点击`生成文件`则只需勾选 `predict()` 函数的cell，即【**模型预测代码答题区域**】的 cell。\n",
    "4. 请导入必要的包和第三方库 (包括此文件中曾经导入过的)。\n",
    "5. 请加载你认为训练最佳的模型，即请按要求填写**模型路径**。\n",
    "6. `predict()`函数的输入和输出请不要改动。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f479f1c",
   "metadata": {},
   "source": [
    "===========================================  **模型预测代码答题区域**  =========================================== \n",
    "\n",
    "在下方的代码块中编写 **模型预测** 部分的代码，请勿在别的位置作答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4b3a3c",
   "metadata": {
    "select": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric.transforms as T\n",
    "from utils import DGraphFin\n",
    "from utils.evaluator import Evaluator\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# ==================== 1. 设置设备（GPU 或 CPU） ====================\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "'''\n",
    "# ==================== 2. 数据加载和预处理 ====================\n",
    "# 数据路径设置\n",
    "path = './datasets/632d74d4e2843a53167ee9a1-momodel/'  # 数据保存路径\n",
    "save_dir = './results/'  # 模型保存路径\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "dataset_name = 'DGraph'  # 数据集名称\n",
    "\n",
    "# 加载数据集\n",
    "dataset = DGraphFin(root=path, name=dataset_name, transform=T.ToSparseTensor())\n",
    "nlabels = 2  # 仅需预测类别 0 和类别 1\n",
    "data = dataset[0]\n",
    "data.adj_t = data.adj_t.to_symmetric()  # 将有向图转换为无向图\n",
    "\n",
    "# 数据预处理\n",
    "x = data.x\n",
    "x = (x - x.mean(0)) / x.std(0)  # 标准化节点特征\n",
    "data.x = x\n",
    "if data.y.dim() == 2:\n",
    "    data.y = data.y.squeeze(1)  # 如果标签维度为 2，则压缩为 1 维\n",
    "\n",
    "# 划分训练集、验证集和测试集\n",
    "split_idx = {\n",
    "    'train': data.train_mask,\n",
    "    'valid': data.valid_mask,\n",
    "    'test': data.test_mask\n",
    "}\n",
    "train_idx = split_idx['train']\n",
    "\n",
    "# 将数据移动到设备上（GPU 或 CPU）\n",
    "data = data.to(device)\n",
    "\n",
    "# 将稀疏邻接矩阵 adj_t 转换为 edge_index（适用于 SAGEConv）\n",
    "row, col, _ = data.adj_t.coo()  # 获取 COO 格式的行、列索引\n",
    "data.edge_index = torch.stack([row, col], dim=0)  # 构建 edge_index 矩阵，形状为 [2, num_edges]\n",
    "\n",
    "# ==================== 3. 定义模型 ====================\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        # 定义三个 SAGEConv 层\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = SAGEConv(hidden_channels, out_channels)\n",
    "        \n",
    "        # 定义用于残差连接的线性层\n",
    "        self.res1 = nn.Linear(in_channels, hidden_channels) if in_channels != hidden_channels else None\n",
    "        self.res2 = nn.Linear(hidden_channels, hidden_channels)\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        # 重置模型参数\n",
    "        self.conv1.reset_parameters()\n",
    "        self.conv2.reset_parameters()\n",
    "        self.conv3.reset_parameters()\n",
    "        if self.res1:\n",
    "            self.res1.reset_parameters()\n",
    "        self.res2.reset_parameters()\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        # 第一层卷积 + 残差连接\n",
    "        identity = x  # 保存输入以用于残差连接\n",
    "        x = F.relu(self.conv1(x, edge_index))  # 图卷积和激活函数\n",
    "        if self.res1:\n",
    "            identity = self.res1(identity)  # 如果维度不同，调整维度\n",
    "        x1 = x + identity  # 残差连接\n",
    "        \n",
    "        # 第二层卷积 + 残差连接\n",
    "        identity = x1\n",
    "        x = F.relu(self.conv2(x1, edge_index))\n",
    "        x2 = x + self.res2(identity)  # 残差连接\n",
    "        \n",
    "        # 第三层卷积（输出层）\n",
    "        x3 = self.conv3(x2, edge_index)\n",
    "        \n",
    "        # 使用 Log Softmax 获取类别概率\n",
    "        return F.log_softmax(x3, dim=-1)\n",
    "\n",
    "# 实例化模型并移动到设备上\n",
    "in_channels = data.x.size(-1)  # 输入特征维度\n",
    "hidden_channels = 128            # 隐藏层维度\n",
    "out_channels = nlabels         # 输出类别数\n",
    "model = GraphSAGE(\n",
    "    in_channels=in_channels,\n",
    "    hidden_channels=hidden_channels,\n",
    "    out_channels=out_channels\n",
    ").to(device)\n",
    "\n",
    "# ==================== 4. 定义训练和评估函数 ====================\n",
    "# 训练超参数设置\n",
    "epochs = 2000           # 训练轮数\n",
    "lr = 0.005              # 学习率\n",
    "weight_decay = 2e-4     # 权重衰减（L2 正则化系数）\n",
    "\n",
    "# 优化器和损失函数\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "# 评估器\n",
    "eval_metric = 'auc'  # 使用 AUC 作为评估指标\n",
    "evaluator = Evaluator(eval_metric)\n",
    "\n",
    "# 定义训练函数\n",
    "def train(model, data, train_idx, optimizer):\n",
    "    model.train()  # 设置模型为训练模式\n",
    "    optimizer.zero_grad()  # 清空梯度\n",
    "    out = model(data.x, data.edge_index)  # 前向传播\n",
    "    loss = F.nll_loss(out[train_idx], data.y[train_idx])  # 计算损失（负对数似然损失）\n",
    "    loss.backward()  # 反向传播\n",
    "    optimizer.step()  # 更新参数\n",
    "    return loss.item()  # 返回损失值\n",
    "\n",
    "# 定义测试函数\n",
    "def test(model, data, split_idx, evaluator):\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index)  # 前向传播\n",
    "        y_pred = out.exp()  # 将 Log Softmax 输出转换为概率\n",
    "        eval_results = {}\n",
    "        losses = {}\n",
    "        for key in ['train', 'valid']:\n",
    "            node_id = split_idx[key]\n",
    "            losses[key] = F.nll_loss(out[node_id], data.y[node_id]).item()  # 计算损失\n",
    "            # 计算评估指标（AUC）\n",
    "            eval_results[key] = evaluator.eval(data.y[node_id], y_pred[node_id])[eval_metric]\n",
    "    return eval_results, losses  # 返回评估结果和损失\n",
    "\n",
    "# ==================== 5. 训练模型 ====================\n",
    "best_valid_auc = 0  # 初始化最佳验证集 AUC\n",
    "best_model_state = None  # 用于保存最佳模型状态\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train(model, data, train_idx, optimizer)  # 训练一步\n",
    "    eval_results, losses = test(model, data, split_idx, evaluator)  # 在训练集和验证集上测试\n",
    "    train_auc = eval_results['train']\n",
    "    valid_auc = eval_results['valid']\n",
    "    \n",
    "    if valid_auc > best_valid_auc:\n",
    "        best_valid_auc = valid_auc\n",
    "        best_model_state = model.state_dict()  # 保存当前最佳模型状态\n",
    "        # 保存最佳模型\n",
    "        model_filename = f'best_sage_model_conv3_hidden{hidden_channels}_lr{lr}_wd{weight_decay}.pt'\n",
    "        torch.save(best_model_state, os.path.join(save_dir, model_filename))\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'第 {epoch:04d} 轮，损失值：{loss:.4f}，训练集 AUC：{train_auc * 100:.2f}% ，验证集 AUC：{valid_auc * 100:.2f}%')\n",
    "\n",
    "print(\"训练完成。\")\n",
    "print(f\"最佳验证集 AUC：{best_valid_auc * 100:.2f}%\")\n",
    "print(f\"最佳模型已保存至 {os.path.join(save_dir, model_filename)}\")\n",
    "\n",
    "# ==================== 6. 保存并加载最佳模型 ====================\n",
    "# 加载最佳模型\n",
    "model.load_state_dict(torch.load(os.path.join(save_dir, model_filename), map_location=device))\n",
    "\n",
    "# ==================== 7. 定义测试并保存预测结果的函数 ====================\n",
    "def test_and_save_predictions(model, data, save_path):\n",
    "    \"\"\"\n",
    "    运行模型的前向传播，并保存所有节点的预测结果\n",
    "    :param model: 训练好的模型\n",
    "    :param data: 包含节点特征和边的图数据\n",
    "    :param save_path: 保存预测结果的文件路径\n",
    "    \"\"\"\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    with torch.no_grad():\n",
    "        # 对所有节点进行前向传播\n",
    "        out = model(data.x, data.edge_index)\n",
    "        y_pred = out.exp()  # 将 Log Softmax 输出转换为概率\n",
    "\n",
    "    # 保存预测结果\n",
    "    torch.save(y_pred.cpu(), save_path)\n",
    "    print(f\"预测结果已保存至 {save_path}\")\n",
    "\n",
    "# 运行模型并保存预测结果\n",
    "predictions_save_path = os.path.join(\n",
    "    save_dir,\n",
    "    f'best_sage_model_conv3_hidden{hidden_channels}_lr{lr}_wd{weight_decay}_predictions.pt'\n",
    ")\n",
    "test_and_save_predictions(model, data, predictions_save_path)\n",
    "'''\n",
    "\n",
    "# ==================== 8. 定义测试-预测函数 ====================\n",
    "def predict(data, node_id):\n",
    "    \"\"\"\n",
    "    加载模型并在 MoAI 平台进行预测\n",
    "    :param data: 数据对象，包含 x 和 edge_index 等属性\n",
    "    :param node_id: int，需要进行预测的节点索引\n",
    "    :return: tensor，类别 0 和类别 1 的概率\n",
    "    \"\"\"\n",
    "    out = model\n",
    "    y_pred = out[node_id].exp() # 获取指定节点的预测概率，并增加一个维度\n",
    "    \n",
    "    return y_pred  # 返回预测概率\n",
    "\n",
    "model = torch.load('./results/best_sage_model_conv3_hidden128_lr0.002_wd0.0002_predictions.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zju_ai_sys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
