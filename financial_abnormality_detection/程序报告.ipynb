{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 金融异常检测任务 - 程序报告\n",
    "\n",
    "吴天宇 12334125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 实验概要\n",
    "\n",
    "### 1.1 实验内容\n",
    "\n",
    "本实验旨在利用图神经网络（Graph Neural Networks）和多层感知机（MLP）在金融领域进行异常检测，识别欺诈用户。我们将基于 DGraph-Fin 数据集，该数据集包含用户之间的社交网络关系和节点特征。\n",
    "\n",
    "实验主要包括以下内容：\n",
    "\n",
    " - 使用 PyTorch 和 PyTorch Geometric 进行图数据的加载和预处理。\n",
    "\n",
    " - 定义并训练多层感知机（MLP）模型和 GraphSAGE 模型。\n",
    "\n",
    " - 评估模型在节点分类任务中的性能，主要使用 AUC（Area Under the Curve）作为评估指标。\n",
    "\n",
    " - 分析模型的训练过程和结果。\n",
    "\n",
    "### 1.2 实验结果概要\n",
    "\n",
    "在本实验中，我们分别训练了 MLP 模型和 GraphSAGE 模型。通过对比，我们发现：\n",
    "\n",
    " - MLP 模型：只利用节点的特征信息，未考虑图结构，训练速度较快，但在验证集上的 AUC 表现有限。\n",
    "\n",
    " - GraphSAGE 模型：结合了节点的特征和邻居信息，通过图卷积捕捉节点之间的关系，在验证集上取得了更高的 AUC。\n",
    "\n",
    "最终，GraphSAGE 模型在验证集上取得了更优的性能，证明了利用图结构信息对于金融异常检测任务的重要性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 多层感知机 MLP 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch_geometric.transforms as T\n",
    "from utils import DGraphFin\n",
    "from utils.evaluator import Evaluator\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 数据加载和预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 数据加载和预处理 ====================\n",
    "# 路径和参数设置\n",
    "path = './datasets/632d74d4e2843a53167ee9a1-momodel/'  # 数据保存路径\n",
    "save_dir = './results/'  # 模型保存路径\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "dataset_name = 'DGraph'  # 数据集名称\n",
    "\n",
    "dataset = DGraphFin(root=path, name=dataset_name, transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "\n",
    "# 数据预处理\n",
    "x = data.x\n",
    "x = (x - x.mean(0)) / x.std(0)  # 标准化节点特征\n",
    "data.x = x\n",
    "    \n",
    "# 划分训练集、验证集和测试集\n",
    "split_idx = {\n",
    "    'train': data.train_mask,\n",
    "    'valid': data.valid_mask,\n",
    "    'test': data.test_mask\n",
    "}\n",
    "train_idx = split_idx['train']\n",
    "\n",
    "# 将数据移动到设备上（GPU 或 CPU）\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 定义模型 ====================\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, dropout, batchnorm=True):\n",
    "        super(MLP, self).__init__()\n",
    "        # 定义多层感知机结构\n",
    "        self.lins = nn.ModuleList([nn.Linear(in_channels, hidden_channels)])\n",
    "        self.bns = nn.ModuleList([nn.BatchNorm1d(hidden_channels)]) if batchnorm else None\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(nn.Linear(hidden_channels, hidden_channels))\n",
    "            if batchnorm:\n",
    "                self.bns.append(nn.BatchNorm1d(hidden_channels))\n",
    "        self.lins.append(nn.Linear(hidden_channels, out_channels))\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        #重置模型参数\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "        if self.bns:\n",
    "            for bn in self.bns:\n",
    "                bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        #模型前向传播\n",
    "        for i, lin in enumerate(self.lins[:-1]):\n",
    "            x = lin(x)\n",
    "            if self.bns:\n",
    "                x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        return F.log_softmax(x, dim=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 训练和评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 训练和评估函数 ====================\n",
    "# 训练超参数设置\n",
    "num_layers = 5\n",
    "hidden_channels = 128\n",
    "\n",
    "mlp_parameters = {'num_layers': num_layers, 'hidden_channels':hidden_channels, 'dropout': 0.5, 'batchnorm': True}\n",
    "in_channels, out_channels = data.x.size(-1), 2\n",
    "model = MLP(in_channels, **mlp_parameters, out_channels=out_channels).to(device)\n",
    "\n",
    "# 优化器和损失函数\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "\n",
    "# 评估器\n",
    "evaluator = Evaluator('auc')\n",
    "\n",
    "def train(model, data, train_idx, optimizer):\n",
    "    \"\"\"\n",
    "    训练模型\n",
    "    :param model: 模型对象\n",
    "    :param data: 数据对象\n",
    "    :param train_idx: 训练集索引\n",
    "    :param optimizer: 优化器\n",
    "    :return: 损失值\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x[train_idx])\n",
    "    loss = F.nll_loss(out, data.y[train_idx].squeeze().long())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def test(model, data, split_idx, evaluator):\n",
    "    \"\"\"\n",
    "    测试模型性能\n",
    "    :param model: 模型对象\n",
    "    :param data: 数据对象\n",
    "    :param split_idx: 数据集划分字典\n",
    "    :param evaluator: 评估器\n",
    "    :return: 评估结果、损失和预测值\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        losses, eval_results = {}, {}\n",
    "        for key in ['train', 'valid']:\n",
    "            node_id = split_idx[key]\n",
    "            out = model(data.x[node_id])\n",
    "            y_pred = out.exp()\n",
    "            losses[key] = F.nll_loss(out, data.y[node_id].squeeze().long()).item()\n",
    "            eval_results[key] = evaluator.eval(data.y[node_id].squeeze().long(), y_pred)['auc']\n",
    "    return eval_results, losses, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 训练模型 ====================\n",
    "def train_model(model, data, split_idx, optimizer, evaluator, save_dir, epochs=1000, log_steps=10):\n",
    "    \"\"\"\n",
    "    执行模型训练并保存最佳模型。\n",
    "    :param model: 模型对象\n",
    "    :param data: 数据对象\n",
    "    :param split_idx: 数据集划分字典\n",
    "    :param optimizer: 优化器\n",
    "    :param evaluator: 评估器\n",
    "    :param save_dir: 模型保存路径\n",
    "    :param epochs: 训练轮数\n",
    "    :param log_steps: 日志记录频率\n",
    "    \"\"\"\n",
    "    best_valid_auc, min_valid_loss = 0, float('inf')\n",
    "    train_idx = split_idx['train']\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        loss = train(model, data, train_idx, optimizer)\n",
    "        eval_results, losses, _ = test(model, data, split_idx, evaluator)\n",
    "        train_auc, valid_auc = eval_results['train'], eval_results['valid']\n",
    "        train_loss, valid_loss = losses['train'], losses['valid']\n",
    "\n",
    "        # 保存最优模型\n",
    "        if valid_loss < min_valid_loss:\n",
    "            min_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), os.path.join(save_dir, f'best_mlp_model_layers{num_layers}_hidden{hidden_channels}.pt'))\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'第 {epoch:04d} 轮，损失值：{loss:.4f}，训练集 AUC：{train_auc * 100:.2f}% ，验证集 AUC：{valid_auc * 100:.2f}%')\n",
    "            \n",
    "train_model(model, data, split_idx, optimizer, evaluator, save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 保存并加载最佳模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 保存并加载最佳模型 ====================\n",
    "def load_best_model(model, save_dir):\n",
    "    \"\"\"\n",
    "    加载最佳模型权重。\n",
    "    :param model: 模型对象\n",
    "    :param save_dir: 模型保存路径\n",
    "    :return: 加载权重后的模型\n",
    "    \"\"\"\n",
    "    model.load_state_dict(torch.load(os.path.join(save_dir, 'best_mlp_model.pt')))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 测试函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 测试函数 ====================\n",
    "def predict(model, data, node_id):\n",
    "    \"\"\"\n",
    "    预测指定节点的标签概率。\n",
    "    :param model: 训练好的模型\n",
    "    :param data: 数据对象\n",
    "    :param node_id: 节点索引\n",
    "    :return: 节点的预测概率\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x[node_id].unsqueeze(0))\n",
    "        y_pred = out.exp()\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 图神经网络 GraphSAGE 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric.transforms as T\n",
    "from utils import DGraphFin\n",
    "from utils.evaluator import Evaluator\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 数据加载和预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 数据加载和预处理 ====================\n",
    "# 数据路径设置\n",
    "path = './datasets/632d74d4e2843a53167ee9a1-momodel/'  # 数据保存路径\n",
    "save_dir = './results/'  # 模型保存路径\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "dataset_name = 'DGraph'  # 数据集名称\n",
    "\n",
    "# 加载数据集\n",
    "dataset = DGraphFin(root=path, name=dataset_name, transform=T.ToSparseTensor())\n",
    "nlabels = 2  # 仅需预测类别 0 和类别 1\n",
    "data = dataset[0]\n",
    "data.adj_t = data.adj_t.to_symmetric()  # 将有向图转换为无向图\n",
    "\n",
    "# 数据预处理\n",
    "x = data.x\n",
    "x = (x - x.mean(0)) / x.std(0)  # 标准化节点特征\n",
    "data.x = x\n",
    "if data.y.dim() == 2:\n",
    "    data.y = data.y.squeeze(1)  # 如果标签维度为 2，则压缩为 1 维\n",
    "\n",
    "# 划分训练集、验证集和测试集\n",
    "split_idx = {\n",
    "    'train': data.train_mask,\n",
    "    'valid': data.valid_mask,\n",
    "    'test': data.test_mask\n",
    "}\n",
    "train_idx = split_idx['train']\n",
    "\n",
    "# 将数据移动到设备上（GPU 或 CPU）\n",
    "data = data.to(device)\n",
    "\n",
    "# 将稀疏邻接矩阵 adj_t 转换为 edge_index（适用于 SAGEConv）\n",
    "row, col, _ = data.adj_t.coo()  # 获取 COO 格式的行、列索引\n",
    "data.edge_index = torch.stack([row, col], dim=0)  # 构建 edge_index 矩阵，形状为 [2, num_edges]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 定义模型 ====================\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        # 定义三个 SAGEConv 层\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = SAGEConv(hidden_channels, out_channels)\n",
    "        \n",
    "        # 定义用于残差连接的线性层\n",
    "        self.res1 = nn.Linear(in_channels, hidden_channels) if in_channels != hidden_channels else None\n",
    "        self.res2 = nn.Linear(hidden_channels, hidden_channels)\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        # 重置模型参数\n",
    "        self.conv1.reset_parameters()\n",
    "        self.conv2.reset_parameters()\n",
    "        self.conv3.reset_parameters()\n",
    "        if self.res1:\n",
    "            self.res1.reset_parameters()\n",
    "        self.res2.reset_parameters()\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        # 第一层卷积 + 残差连接\n",
    "        identity = x  # 保存输入以用于残差连接\n",
    "        x = F.relu(self.conv1(x, edge_index))  # 图卷积和激活函数\n",
    "        if self.res1:\n",
    "            identity = self.res1(identity)  # 如果维度不同，调整维度\n",
    "        x1 = x + identity  # 残差连接\n",
    "        \n",
    "        # 第二层卷积 + 残差连接\n",
    "        identity = x1\n",
    "        x = F.relu(self.conv2(x1, edge_index))\n",
    "        x2 = x + self.res2(identity)  # 残差连接\n",
    "        \n",
    "        # 第三层卷积（输出层）\n",
    "        x3 = self.conv3(x2, edge_index)\n",
    "        \n",
    "        # 使用 Log Softmax 获取类别概率\n",
    "        return F.log_softmax(x3, dim=-1)\n",
    "\n",
    "# 实例化模型并移动到设备上\n",
    "in_channels = data.x.size(-1)  # 输入特征维度\n",
    "hidden_channels = 2            # 隐藏层维度\n",
    "out_channels = nlabels         # 输出类别数\n",
    "model = GraphSAGE(\n",
    "    in_channels=in_channels,\n",
    "    hidden_channels=hidden_channels,\n",
    "    out_channels=out_channels\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 训练和评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 训练和评估函数 ====================\n",
    "# 训练超参数设置\n",
    "epochs = 20           # 训练轮数\n",
    "lr = 0.005              # 学习率\n",
    "weight_decay = 2e-4     # 权重衰减（L2 正则化系数）\n",
    "\n",
    "# 优化器和损失函数\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "# 评估器\n",
    "eval_metric = 'auc'  # 使用 AUC 作为评估指标\n",
    "evaluator = Evaluator(eval_metric)\n",
    "\n",
    "# 定义训练函数\n",
    "def train(model, data, train_idx, optimizer):\n",
    "    model.train()  # 设置模型为训练模式\n",
    "    optimizer.zero_grad()  # 清空梯度\n",
    "    out = model(data.x, data.edge_index)  # 前向传播\n",
    "    loss = F.nll_loss(out[train_idx], data.y[train_idx])  # 计算损失（负对数似然损失）\n",
    "    loss.backward()  # 反向传播\n",
    "    optimizer.step()  # 更新参数\n",
    "    return loss.item()  # 返回损失值\n",
    "\n",
    "# 定义测试函数\n",
    "def test(model, data, split_idx, evaluator):\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index)  # 前向传播\n",
    "        y_pred = out.exp()  # 将 Log Softmax 输出转换为概率\n",
    "        eval_results = {}\n",
    "        losses = {}\n",
    "        for key in ['train', 'valid']:\n",
    "            node_id = split_idx[key]\n",
    "            losses[key] = F.nll_loss(out[node_id], data.y[node_id]).item()  # 计算损失\n",
    "            # 计算评估指标（AUC）\n",
    "            eval_results[key] = evaluator.eval(data.y[node_id], y_pred[node_id])[eval_metric]\n",
    "    return eval_results, losses  # 返回评估结果和损失"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 训练、保存并加载最佳模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 训练、保存并加载最佳模型 ====================\n",
    "best_valid_auc = 0  # 初始化最佳验证集 AUC\n",
    "best_model_state = None  # 用于保存最佳模型状态\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train(model, data, train_idx, optimizer)  # 训练一步\n",
    "    eval_results, losses = test(model, data, split_idx, evaluator)  # 在训练集和验证集上测试\n",
    "    train_auc = eval_results['train']\n",
    "    valid_auc = eval_results['valid']\n",
    "    \n",
    "    if valid_auc > best_valid_auc:\n",
    "        best_valid_auc = valid_auc\n",
    "        best_model_state = model.state_dict()  # 保存当前最佳模型状态\n",
    "        # 保存最佳模型\n",
    "        model_filename = f'best_sage_model_conv3_hidden{hidden_channels}_lr{lr}_wd{weight_decay}.pt'\n",
    "        torch.save(best_model_state, os.path.join(save_dir, model_filename))\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'第 {epoch:04d} 轮，损失值：{loss:.4f}，训练集 AUC：{train_auc * 100:.2f}% ，验证集 AUC：{valid_auc * 100:.2f}%')\n",
    "\n",
    "print(\"训练完成。\")\n",
    "print(f\"最佳验证集 AUC：{best_valid_auc * 100:.2f}%\")\n",
    "print(f\"最佳模型已保存至 {os.path.join(save_dir, model_filename)}\")\n",
    "\n",
    "model.load_state_dict(torch.load(os.path.join(save_dir, model_filename), map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 测试并保存预测结果函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 测试并保存预测结果函数 ====================\n",
    "def test_and_save_predictions(model, data, save_path):\n",
    "    \"\"\"\n",
    "    运行模型的前向传播，并保存所有节点的预测结果\n",
    "    :param model: 训练好的模型\n",
    "    :param data: 包含节点特征和边的图数据\n",
    "    :param save_path: 保存预测结果的文件路径\n",
    "    \"\"\"\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    with torch.no_grad():\n",
    "        # 对所有节点进行前向传播\n",
    "        out = model(data.x, data.edge_index)\n",
    "        y_pred = out.exp()  # 将 Log Softmax 输出转换为概率\n",
    "\n",
    "    # 保存预测结果\n",
    "    torch.save(y_pred.cpu(), save_path)\n",
    "    print(f\"预测结果已保存至 {save_path}\")\n",
    "\n",
    "# 运行模型并保存预测结果\n",
    "predictions_save_path = os.path.join(\n",
    "    save_dir,\n",
    "    f'best_sage_model_conv3_hidden{hidden_channels}_lr{lr}_wd{weight_decay}_predictions.pt'\n",
    ")\n",
    "test_and_save_predictions(model, data, predictions_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 测试-预测函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 测试-预测函数 ====================\n",
    "def predict(data, node_id):\n",
    "    \"\"\"\n",
    "    加载模型并在 MoAI 平台进行预测\n",
    "    :param data: 数据对象，包含 x 和 edge_index 等属性\n",
    "    :param node_id: int，需要进行预测的节点索引\n",
    "    :return: tensor，类别 0 和类别 1 的概率\n",
    "    \"\"\"\n",
    "    out = model\n",
    "    y_pred = out[node_id].exp() # 获取指定节点的预测概率，并增加一个维度\n",
    "    \n",
    "    return y_pred  # 返回预测概率\n",
    "\n",
    "model = torch.load('./results/best_sage_model_conv3_hidden128_lr0.002_wd0.0002_predictions.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zju_ai_sys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
